{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Classification_MLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "uWeTyR2yN2zz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading in data\n",
        "train_data = datasets.MNIST(root='./mnist_data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_data = datasets.MNIST(root='./mnist_data', train=False, download=False, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "mCJAAzYUOKtv"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[25]\n",
        "print('Number of images in Training data: ', len(train_data))\n",
        "print('Shape of a random image from train data is: ', image.shape, label)\n",
        "\n",
        "# plotting the image\n",
        "plt.imshow(image.reshape(28,28), cmap = 'gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "jpk4GmwIOgEv",
        "outputId": "f0576e25-26c0-4421-8cba-c4be659ca6ec"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in Training data:  60000\n",
            "Shape of a random image from train data is:  torch.Size([1, 28, 28]) 2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f22a9fddc50>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAORklEQVR4nO3df4xVdXrH8c9TyqKB/QNWS0ZQ2UWi2TSUbYgxqTQSsquVGCBGA1GjlGT8Y42LadLBbRRQ1phaa8I/xFkhTBvqipFVszFhLWCxmhhHYhWd7koRBTIwKiYzmOgqPP1jDmbAOd873HPOPRee9yuZzL3nmXPOkxs+nHPPr6+5uwCc//6s7gYAtAZhB4Ig7EAQhB0IgrADQfx5K1dmZhz6Byrm7jba9EJbdjO7wcz+YGb7zGxVkWUBqJY1e57dzMZJ+qOkn0o6JOlNScvc/f3EPGzZgYpVsWW/WtI+d9/v7n+S9BtJiwosD0CFioR9mqSDI94fyqadxsw6zazXzHoLrAtAQZUfoHP3bkndErvxQJ2KbNkPS7p0xPvp2TQAbahI2N+UNMvMfmhm35O0VNKL5bQFoGxN78a7+zdmdo+k7ZLGSdrk7u+V1hmAUjV96q2plfGdHahcJRfVADh3EHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQREuHbEbr3Xzzzcn6BRdckKzPnTs3WV+5cmWyvmvXrtzaxo0bk/P29fUl63v27EnWcTq27EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBKO4toELL7wwWb/yyiuT9Ycffji3tmDBguS8EyZMSNbr9OGHHybrO3fuTNa7urpya4ODg8l5T5w4kay3s7xRXAtdVGNmByQNSToh6Rt3T1+BAaA2ZVxBN9/dPy1hOQAqxHd2IIiiYXdJvzezt8ysc7Q/MLNOM+s1s96C6wJQQNHd+Gvd/bCZ/YWkl83sf91998g/cPduSd0SB+iAOhXasrv74ez3gKTfSrq6jKYAlK/psJvZRDP7/qnXkn4maW9ZjQEoV9Pn2c3sRxremkvDXwf+w91/1WCe83I3fvbs2cn6vHnzkvXrr78+WV+4cOFZ94S0tWvXJuvbtm1L1vfubd/tWunn2d19v6S/arojAC3FqTcgCMIOBEHYgSAIOxAEYQeC4FHSJWh0am39+vUt6uS7Pv7442S9zls5Ozo6kvVGj7kuYvXq1cn6J598kqy386m3PGzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIzrO3wPPPP5+sL168OFk/cuRIsv7UU0/l1h577LHkvMePH0/Wq3Tvvfcm60888USLOomBLTsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBMGQzSWYPHlyst7onvFLLrkkWf/yyy+T9QMHDiTr7eqaa65J1l977bXK1v3FF18k6ytWrEjWn3322TLbKVXeo6TZsgNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAENzPXoLPP/+80PyDg4MlddJ648ePT9YfeeSR3Nott9xSdjtj1tXVlay383n0ZjXcspvZJjMbMLO9I6ZNMbOXzeyD7Hf6qhIAtRvLbvxmSTecMW2VpB3uPkvSjuw9gDbWMOzuvlvSsTMmL5LUk73ukZR+rhKA2jX7nX2qu/dnr49Impr3h2bWKamzyfUAKEnhA3Tu7qkbXNy9W1K3dP7eCAOcC5o99XbUzDokKfs9UF5LAKrQbNhflHRn9vpOSS+U0w6AqjS8n93MnpZ0naSLJB2VtFrS85K2SrpM0keSbnX3Mw/ijbYsduPPMfPnz0/W77vvvmR94cKFZbZzVvbv359bmzdvXnLeRs/qb2d597M3/M7u7stySgsKdQSgpbhcFgiCsANBEHYgCMIOBEHYgSC4xTW45cuXJ+tPPvlksj5u3Lgy2zkrDz30ULKeGir7XD611iy27EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBOfZzwOzZ8/OrS1atCg57wMPPJCsV3kevdFQ1C+99FKy3tPTk6yfq0NZV4UtOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4E0fBR0qWujEdJj6rRsMczZ85M1l94If+x/VdccUVTPZ1y4sSJZP3rr79uetkPPvhgsv744483vezI8h4lzZYdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4LgfvY20NXVlayvXbu2snW/+uqryfozzzyTrG/YsKHMdlChhlt2M9tkZgNmtnfEtDVmdtjM3s5+bqy2TQBFjWU3frOkG0aZ/oS7z8l+0o8UAVC7hmF3992SjrWgFwAVKnKA7h4zeyfbzZ+c90dm1mlmvWbWW2BdAApqNuwbJM2UNEdSv6TcOxbcvdvd57r73CbXBaAETYXd3Y+6+wl3Pynp15KuLrctAGVrKuxm1jHi7RJJe/P+FkB7aHie3cyelnSdpIvM7JCk1ZKuM7M5klzSAUl3V9hj25s4cWKy3uie8rvuuqvEbk63a9euZP2OO+5I1vv7+8tsBzVqGHZ3XzbK5I0V9AKgQlwuCwRB2IEgCDsQBGEHgiDsQBDc4lqCRqfO1q9fX+n6X3nlldzakiVLkvMODQ2V3A3aFVt2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCIZvH6Kqrrsqtbd++PTnv9OnTC617x44dyfrtt9+eWxsYGCi07ipdfvnlyXqjW4fXrVtXaPlFHD9+PFm///77k/XXX3+9zHZOw5DNQHCEHQiCsANBEHYgCMIOBEHYgSAIOxAE97Nn5syZk6xv3bo1t1b0PHoj+/btS9ZnzZqVWyt6nn3NmjXJ+rhx45pe9m233ZasV3mevKjly5cn61WeR28WW3YgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCILz7JlG57J37tyZW5s5c2bZ7Zzm7rvTI2LfeuutubXBwcFC677sssuSdbNRb50+702bNq3uFs5awy27mV1qZrvM7H0ze8/MfpFNn2JmL5vZB9nvydW3C6BZY9mN/0bSP7j7jyVdI+nnZvZjSask7XD3WZJ2ZO8BtKmGYXf3fnffk70ektQnaZqkRZJ6sj/rkbS4qiYBFHdW39nNbIakn0h6Q9JUd+/PSkckTc2Zp1NSZ/MtAijDmI/Gm9kkSc9JWunupx318eGnVo76MEl373b3ue4+t1CnAAoZU9jNbLyGg77F3bdlk4+aWUdW75DUvo8xBdD4UdI2fG6lR9Ixd185Yvpjkj5z90fNbJWkKe7+jw2Wdc4+SnrChAm5tc2bNyfnTZ0aQz1Wr16drH/22WfJ+qZNm5L1r7766qx7Kkveo6TH8p39byTdIeldM3s7m/ZLSY9K2mpmKyR9JIl/0UAbaxh2d/9vSXlXTiwotx0AVeFyWSAIwg4EQdiBIAg7EARhB4LgFtcxSp033bJlS3Leiy++OFmfP39+Uz2dCw4ePJhbW7p0aXLevr6+stv51tDQULJ+8uTJytZdF7bsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxBEw/vZS13ZOXw/exGTJk1K1m+66aZkfcaMGcn6unXrzralb3V3dyfru3fvbnrZkrR///7c2htvvFFo2Rhd3v3sbNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjOswPnGc6zA8ERdiAIwg4EQdiBIAg7EARhB4Ig7EAQDcNuZpea2S4ze9/M3jOzX2TT15jZYTN7O/u5sfp2ATSr4UU1ZtYhqcPd95jZ9yW9JWmxhsdjP+7u/zLmlXFRDVC5vItqxjI+e7+k/uz1kJn1SZpWbnsAqnZW39nNbIakn0g69Tyhe8zsHTPbZGaTc+bpNLNeM+st1CmAQsZ8bbyZTZL0X5J+5e7bzGyqpE8luaSHNbyr//cNlsFuPFCxvN34MYXdzMZL+p2k7e7+r6PUZ0j6nbv/ZYPlEHagYk3fCGNmJmmjpL6RQc8O3J2yRNLeok0CqM5YjsZfK+lVSe9KOjWO7S8lLZM0R8O78Qck3Z0dzEstiy07ULFCu/FlIexA9bifHQiOsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EETDB06W7FNJH414f1E2rR21a2/t2pdEb80qs7fL8wotvZ/9Oys363X3ubU1kNCuvbVrXxK9NatVvbEbDwRB2IEg6g57d83rT2nX3tq1L4nemtWS3mr9zg6gderesgNoEcIOBFFL2M3sBjP7g5ntM7NVdfSQx8wOmNm72TDUtY5Pl42hN2Bme0dMm2JmL5vZB9nvUcfYq6m3thjGOzHMeK2fXd3Dn7f8O7uZjZP0R0k/lXRI0puSlrn7+y1tJIeZHZA0191rvwDDzP5W0nFJ/3ZqaC0z+2dJx9z90ew/ysnu3tUmva3RWQ7jXVFvecOM36UaP7syhz9vRh1b9qsl7XP3/e7+J0m/kbSohj7anrvvlnTsjMmLJPVkr3s0/I+l5XJ6awvu3u/ue7LXQ5JODTNe62eX6Ksl6gj7NEkHR7w/pPYa790l/d7M3jKzzrqbGcXUEcNsHZE0tc5mRtFwGO9WOmOY8bb57JoZ/rwoDtB917Xu/teS/k7Sz7Pd1bbkw9/B2unc6QZJMzU8BmC/pMfrbCYbZvw5SSvdfXBkrc7PbpS+WvK51RH2w5IuHfF+ejatLbj74ez3gKTfavhrRzs5emoE3ez3QM39fMvdj7r7CXc/KenXqvGzy4YZf07SFnfflk2u/bMbra9WfW51hP1NSbPM7Idm9j1JSyW9WEMf32FmE7MDJzKziZJ+pvYbivpFSXdmr++U9EKNvZymXYbxzhtmXDV/drUPf+7uLf+RdKOGj8j/n6R/qqOHnL5+JOl/sp/36u5N0tMa3q37WsPHNlZI+oGkHZI+kPSfkqa0UW//ruGhvd/RcLA6aurtWg3vor8j6e3s58a6P7tEXy353LhcFgiCA3RAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EMT/A9SJgeRGoKlIAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "F_Oj9OxEOx6M"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Netwrok Architecture\n",
        "\n",
        "--- Input Layers --- 784 neurons - input of 28 * 28\n",
        "\n",
        "\n",
        "--- Hidden Layer --- 256 neurons\n",
        "\n",
        "\n",
        "--- Output Layer --- 10 neurons - 0 to 9 digits to classify from\n",
        "\n",
        "We will use relu activation function and we will use softmax rto give us the probabilities at the output layer"
      ],
      "metadata": {
        "id": "1UhGl0qkQkFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model\n",
        "class MNIST_classifier(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(MNIST_classifier, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "  def forward(self, input):\n",
        "    out1 = self.fc1(input)\n",
        "    out1 = self.act(out1)\n",
        "    final_out = self.fc2(out1)\n",
        "\n",
        "    return final_out\n"
      ],
      "metadata": {
        "id": "beu-kKXYRQyt"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining hyperparameters\n",
        "input_size = 784\n",
        "hidden_size = 256\n",
        "output_size = 10\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "i2lefdMDT4th"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNIST_classifier(input_size, hidden_size, output_size).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "OvyoYqspVL7y"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the network\n",
        "print('\\n Training model on training dataset \\n')\n",
        "for epoch in range(epochs):\n",
        "  for batch_index, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(device=device)\n",
        "    labels = labels.to(device=device) \n",
        "\n",
        "    # Getting data in the correct shape\n",
        "    images = images.view(-1, 784)\n",
        "\n",
        "    # Forward Propogation\n",
        "    predictions = model(images)\n",
        "    loss = criterion(predictions, labels)\n",
        "\n",
        "    # Backward Propogation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Gradient Descent\n",
        "    optimizer.step()\n",
        "  \n",
        "    if batch_index % 100 == 0:\n",
        "      print(f'Epoch {epoch+1}, batch number {batch_index+100}, loss is {loss}')\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmGYJhjzVlQL",
        "outputId": "bee62b5e-8621-4bf5-d910-336b55496b4f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Training model on training dataset \n",
            "\n",
            "Epoch 1, batch number 100, loss is 2.3062267303466797\n",
            "Epoch 1, batch number 200, loss is 0.43779197335243225\n",
            "Epoch 1, batch number 300, loss is 0.21239660680294037\n",
            "Epoch 1, batch number 400, loss is 0.37343403697013855\n",
            "Epoch 1, batch number 500, loss is 0.2786595821380615\n",
            "Epoch 1, batch number 600, loss is 0.22813086211681366\n",
            "Epoch 2, batch number 100, loss is 0.24473904073238373\n",
            "Epoch 2, batch number 200, loss is 0.11922585219144821\n",
            "Epoch 2, batch number 300, loss is 0.11561247706413269\n",
            "Epoch 2, batch number 400, loss is 0.1427127718925476\n",
            "Epoch 2, batch number 500, loss is 0.1802217662334442\n",
            "Epoch 2, batch number 600, loss is 0.09787431359291077\n",
            "Epoch 3, batch number 100, loss is 0.08286131173372269\n",
            "Epoch 3, batch number 200, loss is 0.11686652153730392\n",
            "Epoch 3, batch number 300, loss is 0.12697206437587738\n",
            "Epoch 3, batch number 400, loss is 0.06710396707057953\n",
            "Epoch 3, batch number 500, loss is 0.05593651905655861\n",
            "Epoch 3, batch number 600, loss is 0.10153621435165405\n",
            "Epoch 4, batch number 100, loss is 0.09335426986217499\n",
            "Epoch 4, batch number 200, loss is 0.0780380591750145\n",
            "Epoch 4, batch number 300, loss is 0.04605643451213837\n",
            "Epoch 4, batch number 400, loss is 0.05164274573326111\n",
            "Epoch 4, batch number 500, loss is 0.04117603227496147\n",
            "Epoch 4, batch number 600, loss is 0.12418794631958008\n",
            "Epoch 5, batch number 100, loss is 0.03979968652129173\n",
            "Epoch 5, batch number 200, loss is 0.03408987820148468\n",
            "Epoch 5, batch number 300, loss is 0.029552482068538666\n",
            "Epoch 5, batch number 400, loss is 0.03354211151599884\n",
            "Epoch 5, batch number 500, loss is 0.03366893157362938\n",
            "Epoch 5, batch number 600, loss is 0.0490022711455822\n",
            "Epoch 6, batch number 100, loss is 0.044687770307064056\n",
            "Epoch 6, batch number 200, loss is 0.020016919821500778\n",
            "Epoch 6, batch number 300, loss is 0.0446423664689064\n",
            "Epoch 6, batch number 400, loss is 0.037689123302698135\n",
            "Epoch 6, batch number 500, loss is 0.05348619446158409\n",
            "Epoch 6, batch number 600, loss is 0.0457274429500103\n",
            "Epoch 7, batch number 100, loss is 0.07554564625024796\n",
            "Epoch 7, batch number 200, loss is 0.039822839200496674\n",
            "Epoch 7, batch number 300, loss is 0.07930614054203033\n",
            "Epoch 7, batch number 400, loss is 0.03049248643219471\n",
            "Epoch 7, batch number 500, loss is 0.05079018697142601\n",
            "Epoch 7, batch number 600, loss is 0.04657278209924698\n",
            "Epoch 8, batch number 100, loss is 0.03380345180630684\n",
            "Epoch 8, batch number 200, loss is 0.008452477864921093\n",
            "Epoch 8, batch number 300, loss is 0.016316181048750877\n",
            "Epoch 8, batch number 400, loss is 0.10466407984495163\n",
            "Epoch 8, batch number 500, loss is 0.020306741818785667\n",
            "Epoch 8, batch number 600, loss is 0.039327263832092285\n",
            "Epoch 9, batch number 100, loss is 0.0142921581864357\n",
            "Epoch 9, batch number 200, loss is 0.03087026998400688\n",
            "Epoch 9, batch number 300, loss is 0.02411147765815258\n",
            "Epoch 9, batch number 400, loss is 0.015819482505321503\n",
            "Epoch 9, batch number 500, loss is 0.0077290004119277\n",
            "Epoch 9, batch number 600, loss is 0.029610032215714455\n",
            "Epoch 10, batch number 100, loss is 0.019984398037195206\n",
            "Epoch 10, batch number 200, loss is 0.0063356137834489346\n",
            "Epoch 10, batch number 300, loss is 0.008966181427240372\n",
            "Epoch 10, batch number 400, loss is 0.005698559805750847\n",
            "Epoch 10, batch number 500, loss is 0.012673554010689259\n",
            "Epoch 10, batch number 600, loss is 0.015998510643839836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Time : Checking accuracy on Test Data\n",
        "def check_accuracy(loader, model):\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device = device)\n",
        "      y = y.to(device = device)\n",
        "      x = x.view(-1, 784)\n",
        "\n",
        "      y_pred = model(x)\n",
        "      # print(y_pred.shape)\n",
        "      values, position = torch.max(y_pred, axis=1)\n",
        "      # print(position, y)\n",
        "      num_correct += (position == y).sum()\n",
        "      num_samples += y.shape[0]\n",
        "\n",
        "      # print(num_correct,'/',num_samples)\n",
        "\n",
        "    accuracy = float((num_correct/num_samples) * 100)\n",
        "    print(f'Accuracy on Test Set is {accuracy}')\n",
        "\n",
        "\n",
        "check_accuracy(test_loader, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu0zOLo_ZRAz",
        "outputId": "3a6b454c-e58a-4792-9fa1-e0e37239c4ed"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Test Set is 97.93000030517578\n"
          ]
        }
      ]
    }
  ]
}